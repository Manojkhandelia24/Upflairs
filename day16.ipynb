{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import face_recognition as fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "vid = cv2.VideoCapture(0)\n",
    "name = input(\"Enter your name: \")\n",
    "frameCount = 0\n",
    "frameLimit = 20\n",
    "names = []\n",
    "enc = []\n",
    "\n",
    "while True:\n",
    "    flag, img = vid.read()\n",
    "    if(flag):\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)                      \n",
    "        faces = fd.detectMultiScale(img_gray, scaleFactor = 1.1, minNeighbors = 5, minSize = (50,50))  \n",
    "\n",
    "        if len(faces) == 1:\n",
    "            x,y,w,h = faces[0]\n",
    "            img_face = img[y:y+h,x:x+w,:].copy()    ## Crop Image\n",
    "            img_face = cv2.resize(img_face, (400,400), cv2.INTER_CUBIC)  ## Resize\n",
    "            face_encoding = fr.face_encodings(img_face)  ## numpy array\n",
    "            \n",
    "            if len(face_encoding) == 1:\n",
    "                enc.append(face_encoding[0].tolist())   # convert numpy array to list\n",
    "                names.append(name)\n",
    "                frameCount += 1\n",
    "\n",
    "                cv2.putText(img, str(frameCount),(30,30), cv2.FONT_HERSHEY_COMPLEX,1.5,(0,0,255),5)\n",
    "\n",
    "                if frameCount == frameLimit:\n",
    "                    try:\n",
    "                        old_data = pd.read_csv('face_data.csv',index_col = 0,sep='|')\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                    else:\n",
    "                        enc_old = old_data['encoding'].values.tolist()\n",
    "                        names_old = old_data['names'].values.tolist()\n",
    "                        enc = enc_old + enc\n",
    "                        names = names_old + names\n",
    "                    data = {'names' : names, 'encoding' : enc}\n",
    "                    pd.DataFrame(data).to_csv('face_data.csv', sep='|')   # encoding is in string format due to csv\n",
    "                    break\n",
    "            \n",
    "\n",
    "        for x,y,w,h in faces:\n",
    "            cv2.rectangle(img, pt1 = (x,y), pt2 = (x+w, y+h), color = (0,0,255), thickness = 8)\n",
    "       \n",
    "        cv2.imshow('Preview', img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.20861295,  0.08878872,  0.05899967, -0.05886307, -0.00564111,\n",
       "        -0.0223909 , -0.03358044, -0.11925235,  0.2169904 , -0.10323576,\n",
       "         0.23029014, -0.00272163, -0.13647079, -0.15761892,  0.01714007,\n",
       "         0.09929757, -0.1793278 , -0.11831135, -0.01708465, -0.10234946,\n",
       "         0.07254434,  0.03874739, -0.00245316,  0.05968298, -0.20596913,\n",
       "        -0.39804921, -0.11818799, -0.13665186,  0.05851385, -0.08056497,\n",
       "        -0.07493411,  0.00228969, -0.22695132, -0.07335806, -0.0223516 ,\n",
       "         0.12563604,  0.05897357, -0.01820629,  0.12816167,  0.01926452,\n",
       "        -0.17010298, -0.03425704,  0.03655533,  0.23173466,  0.15104046,\n",
       "         0.00330977,  0.02537852, -0.01970627,  0.05500567, -0.11292208,\n",
       "         0.00485475,  0.1287525 ,  0.07783989,  0.02423978,  0.04061939,\n",
       "        -0.1109966 , -0.04032528,  0.0267539 , -0.17141101,  0.02676591,\n",
       "         0.02161042, -0.12006333, -0.06807933,  0.01855613,  0.19015922,\n",
       "         0.07538442, -0.09701644, -0.15945801,  0.15169582, -0.15846591,\n",
       "        -0.02357193,  0.03297136, -0.09476855, -0.18270548, -0.31519854,\n",
       "         0.08112577,  0.45299491,  0.11936299, -0.18356282,  0.12826723,\n",
       "        -0.15558296, -0.07402872,  0.08953649,  0.10915466, -0.02460339,\n",
       "         0.13787654, -0.0738994 ,  0.07082305,  0.18629812,  0.04825007,\n",
       "        -0.02144076,  0.17663114, -0.0321928 ,  0.08950402,  0.05650902,\n",
       "         0.03232802, -0.08717317, -0.00447486, -0.06743854,  0.00054036,\n",
       "         0.05374942, -0.06432995,  0.0070749 ,  0.08786406, -0.20715463,\n",
       "         0.14974315,  0.07507932, -0.06232381, -0.01634345,  0.07276348,\n",
       "        -0.10906827, -0.07276908,  0.12518014, -0.29798442,  0.1668175 ,\n",
       "         0.22049272,  0.02097058,  0.23131585,  0.0896161 ,  0.05155019,\n",
       "         0.01899775,  0.00702943, -0.11898675, -0.07092189,  0.02207072,\n",
       "        -0.05325854,  0.09935208,  0.0296574 ])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_encoding   # numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10054711,  0.11393932,  0.03529228, -0.00211232, -0.12081286,\n",
       "       -0.05728541, -0.0592917 , -0.03165598,  0.18807675, -0.03641161,\n",
       "        0.27207634,  0.02627178, -0.2101852 , -0.11734563, -0.00641376,\n",
       "        0.13493414, -0.15505603, -0.03536628, -0.06196696, -0.10395791,\n",
       "        0.04995011,  0.02163264,  0.02799172,  0.04263721, -0.11208569,\n",
       "       -0.32678869, -0.10542999, -0.13593768,  0.016575  , -0.15060981,\n",
       "       -0.01598203, -0.0265799 , -0.17681035, -0.11761075, -0.00994203,\n",
       "        0.00274021, -0.02268637, -0.07451365,  0.1804453 ,  0.03900331,\n",
       "       -0.15261887, -0.01630871,  0.00725888,  0.29524055,  0.17784765,\n",
       "        0.0251925 , -0.0213203 , -0.07310906,  0.14129542, -0.20742247,\n",
       "        0.05046771,  0.14263734,  0.11081794,  0.02665   ,  0.10274504,\n",
       "       -0.12693709,  0.04746445,  0.11234433, -0.22306657, -0.01374433,\n",
       "        0.0377125 , -0.02520212, -0.04236003, -0.09510267,  0.22651397,\n",
       "        0.12382142, -0.06599275, -0.14620365,  0.11881723, -0.13389261,\n",
       "       -0.03522345,  0.07230173, -0.12208881, -0.22170195, -0.31753647,\n",
       "        0.09346711,  0.42265707,  0.21067861, -0.20269568,  0.01453629,\n",
       "       -0.11921875, -0.04659501,  0.07665008,  0.03201719, -0.08233216,\n",
       "        0.03099588, -0.10113155,  0.02589883,  0.12844957, -0.03837598,\n",
       "       -0.01993875,  0.23351173,  0.00107531,  0.04551067,  0.03855979,\n",
       "       -0.04187026, -0.12751836,  0.03569036, -0.10751856, -0.02499782,\n",
       "        0.08687948, -0.11921243,  0.05312184,  0.08527953, -0.21497175,\n",
       "        0.09615688,  0.0319606 , -0.04095329, -0.01437375,  0.02945557,\n",
       "       -0.14210252, -0.04765006,  0.1767834 , -0.26100111,  0.23468433,\n",
       "        0.15308976,  0.0309935 ,  0.1721883 ,  0.07497212,  0.09358472,\n",
       "       -0.08393787, -0.04942238, -0.10920537, -0.02066616,  0.04437714,\n",
       "       -0.0395356 ,  0.07857137,  0.0092222 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_data = pd.read_csv('face_data.csv',index_col = 0, sep = '|')\n",
    "face_data['encoding'][0]   # string\n",
    "eval(face_data['encoding'][0])\n",
    "np.array(eval(face_data['encoding'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('float64'), dtype('<U2402')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(face_encoding) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     17\u001b[0m     \u001b[39mfor\u001b[39;00m ind, face_db \u001b[39min\u001b[39;00m face_data\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m---> 18\u001b[0m         matched \u001b[39m=\u001b[39m fr\u001b[39m.\u001b[39;49mcompare_faces(face_encoding[\u001b[39m0\u001b[39;49m], face_db[\u001b[39m'\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     19\u001b[0m         \u001b[39mif\u001b[39;00m matched:\n\u001b[0;32m     20\u001b[0m             \u001b[39mprint\u001b[39m(face_db[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\ANUJA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\face_recognition\\api.py:226\u001b[0m, in \u001b[0;36mcompare_faces\u001b[1;34m(known_face_encodings, face_encoding_to_check, tolerance)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompare_faces\u001b[39m(known_face_encodings, face_encoding_to_check, tolerance\u001b[39m=\u001b[39m\u001b[39m0.6\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[39m    Compare a list of face encodings against a candidate encoding to see if they match.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m    :return: A list of True/False values indicating which known_face_encodings match the face encoding to check\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(face_distance(known_face_encodings, face_encoding_to_check) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m tolerance)\n",
      "File \u001b[1;32mc:\\Users\\ANUJA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\face_recognition\\api.py:75\u001b[0m, in \u001b[0;36mface_distance\u001b[1;34m(face_encodings, face_to_compare)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(face_encodings) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mempty((\u001b[39m0\u001b[39m))\n\u001b[1;32m---> 75\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(face_encodings \u001b[39m-\u001b[39;49m face_to_compare, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('float64'), dtype('<U2402')) -> None"
     ]
    }
   ],
   "source": [
    "# Real Time Face Recognition\n",
    "\n",
    "fd = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "old_data = pd.read_csv('face_data.csv',index_col = 0,sep='|')\n",
    "\n",
    "while True:\n",
    "    flag, img = vid.read()\n",
    "    if(flag):\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)                      \n",
    "        faces = fd.detectMultiScale(img_gray, scaleFactor = 1.1, minNeighbors = 5, minSize = (50,50))  \n",
    "\n",
    "        if len(faces) == 1:\n",
    "            x,y,w,h = faces[0]\n",
    "            img_face = img[y:y+h,x:x+w,:].copy()    ## Crop Image\n",
    "            img_face = cv2.resize(img_face, (400,400), cv2.INTER_CUBIC)  ## Resize\n",
    "            face_encoding = fr.face_encodings(img_face)\n",
    "\n",
    "            if len(face_encoding) == 1:\n",
    "                for ind, entries in old_data.iterrows():\n",
    "                    matched = fr.compare_faces(face_encoding, np.array(eval(entries['encoding'])))\n",
    "                    if matched:\n",
    "                        print(entries['names'])\n",
    "                        cv2.putText(img,entries['name'],(30,30),cv2.FONT_HERSHEY_COMPLEX, 1.5, (0,0,255),5)\n",
    "\n",
    "        for x,y,w,h in faces:\n",
    "            cv2.rectangle(img, pt1 = (x,y), pt2 = (x+w, y+h), color = (0,0,255), thickness = 8)\n",
    "       \n",
    "        cv2.imshow('Preview', img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
